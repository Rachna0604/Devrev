{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXi8GB2oZSwHo2yi+fpfmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rachna0604/Devrev/blob/main/FinalDevrev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeUq8jAymGVD"
      },
      "outputs": [],
      "source": [
        "!pip install nltk==3.4.5\n",
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "#for pre processing\n",
        "import csv,numpy \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "Rekxgx44m_ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing g drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSVzZ4brnEgL",
        "outputId": "2226a585-9d66-4fd4-af78-77946c8c5a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "yQREM4zt3khB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting paragraphs from question and theme"
      ],
      "metadata": {
        "id": "8Godp1V5ndOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "def predict_answer(question, paragraphs, theme):\n",
        "    # Filter the paragraphs to only include those with the correct theme\n",
        "    theme_paragraphs = [p['text'] for p in paragraphs if p['theme'] == theme]\n",
        "    \n",
        "    # Create a TfidfVectorizer to convert the paragraphs into numerical vectors\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(theme_paragraphs)\n",
        "    \n",
        "    # Convert the question into a numerical vector\n",
        "    question_vector = vectorizer.transform([question])\n",
        "    \n",
        "    # Calculate the cosine similarity between the question and each paragraph\n",
        "    similarity = cosine_similarity(question_vector, X)\n",
        "    \n",
        "    # Find the paragraph with the highest similarity score\n",
        "    max_similarity_index = similarity.argmax()\n",
        "    max_similarity_score = similarity[0, max_similarity_index]\n",
        "    \n",
        "    # If the maximum similarity score is above a certain threshold, return the paragraph\n",
        "    if max_similarity_score > 0.05:\n",
        "        return theme_paragraphs[max_similarity_index]\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "cxm8h-CHnSx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of France?\"\n",
        "paragraphs = [\n",
        "    {'text': 'Paris is the capital of France', 'theme': 'Geography'},\n",
        "    {'text': 'Lyon is a city in France', 'theme': 'Geography'},\n",
        "    {'text': 'The Pythagorean theorem states that a^2 + b^2 = c^2', 'theme': 'Mathematics'},\n",
        "]\n",
        "\n",
        "# Predict the answer to the question\n",
        "answer = predict_answer(question, paragraphs, 'Geography')\n",
        "\n",
        "# Print the answer\n",
        "if answer:\n",
        "    print(answer)\n",
        "else:\n",
        "    print(\"No suitable paragraph found\")"
      ],
      "metadata": {
        "id": "1zE99rQOnq8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the paragraphs,questions and themes in the way it can be passed through the function predict_answer"
      ],
      "metadata": {
        "id": "BOZVm7YIn1x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/DevRev/train_data.csv'\n",
        "data = pd.read_csv(path)\n",
        "Paragraphs = []\n",
        "for para in data['Paragraph']:\n",
        "    if para not in Paragraphs:\n",
        "        Paragraphs.append(para)\n",
        "questions = []\n",
        "for q in data['Question']:\n",
        "    if q not in questions:\n",
        "          questions.append(q)\n",
        "themes = []\n",
        "for t in data['Theme']:\n",
        "    if t not in themes:\n",
        "        themes.append(t)\n",
        "PT = []\n",
        "Themes = []\n",
        "for element in Paragraphs:\n",
        "    Themes.append(data['Theme'][data.loc[data['Paragraph'] == element]['Theme'].index[0]])\n",
        "for i in range(len(Themes)):\n",
        "    PT.append({'text': Paragraphs[i], 'theme': Themes[i]})\n",
        "question = questions[0]\n",
        "answer = predict_answer(question, PT, 'BeyoncÃ©')\n",
        "if answer:\n",
        "    print(answer)\n",
        "else:\n",
        "    print(\"No suitable paragraph found\")"
      ],
      "metadata": {
        "id": "pPmZDuC8nuvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "mhB46MQO3sBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning a model    \n",
        "**this has no continuation with the above code , it's a seperate method tried "
      ],
      "metadata": {
        "id": "teSM1N1Fo1H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the data from the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DevRev/train_data.csv\")\n",
        "\n",
        "# Preprocess the data\n",
        "df[\"question\"] = df[\"Question\"].str.lower()\n",
        "df[\"paragraph\"] = df[\"Paragraph\"].str.lower()\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[[\"question\", \"paragraph\"]], df[\"Theme\"], test_size=0.2)\n",
        "\n",
        "# Vectorize the data using a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectors = vectorizer.fit_transform(X_train[\"question\"])\n",
        "X_test_vectors = vectorizer.transform(X_test[\"question\"])\n",
        "\n",
        "# Train a support vector machine (SVM) classifier\n",
        "clf = SVC()\n",
        "clf.fit(X_train_vectors, y_train)\n",
        "\n",
        "# Predict the theme labels for the test data\n",
        "y_pred = clf.predict(X_test_vectors)\n",
        "\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate the precision of the model\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Calculate the recall of the model\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Calculate the F1 score of the model\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "Ho3SAOSYpPgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the new question\n",
        "new_question = \"Who was Hayek's father?\"\n",
        "new_question = new_question.lower()\n",
        "\n",
        "# Vectorize the new question\n",
        "new_question_vector = vectorizer.transform([new_question])\n",
        "\n",
        "# Use the model to make a prediction\n",
        "prediction = clf.predict(new_question_vector)[0]\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "MKlguCijpkZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "th08gOx53v4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is another method of approaching the question which I tried earlier, it's not running, but approach can be referred"
      ],
      "metadata": {
        "id": "HB5sM1QRqISS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting_answer(question, paragraphs):\n",
        "  #pre process\n",
        "  question_tokens = preprocess_text(question)\n",
        "  paragraphs_tokens = [preprocess_text(p) for p in paragraphs]\n",
        "  #generate embeddings\n",
        "  question_embeddings = nlp_model(question_tokens)\n",
        "  paragraphs_embeddings = [nlp_model(p) for p in paragraphs_tokens]\n",
        "  #compare embeddings i.e. similarity measure\n",
        "  most_similar_paragraph = find_most_similar(question_embeddings, paragraphs_embeddings)\n",
        "  #threshold\n",
        "  if most_similar_paragraph[1] > SIMILARITY_THRESHOLD:\n",
        "    return paragraphs[most_similar_paragraph[0]]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "jsg0glXnqXWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  # Tokenize the text\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  \n",
        "  # Stem the tokens\n",
        "  stemmer = PorterStemmer()\n",
        "  stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "  \n",
        "  return stemmed_tokens\n",
        "\n",
        "# Pre-process the question\n",
        "question = \"What is the capital of France?\"\n",
        "question_tokens = preprocess_text(question)\n",
        "print(question_tokens)  \n",
        "\n",
        "# Pre-process a paragraph\n",
        "paragraph = \"Paris is the capital of France. It is located in the northern central part of the country and is home to many famous landmarks, including the Eiffel Tower.\"\n",
        "paragraph_tokens = preprocess_text(paragraph)\n",
        "print(paragraph_tokens)  \n"
      ],
      "metadata": {
        "id": "vCjMDtRrqyyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "# Initialize the BERT model and tokenizer\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def generate_embeddings(tokens):\n",
        "  # Encode the text\n",
        "  input_ids = tokenizer(tokens, return_tensors='pt',padding=True,truncation=True)\n",
        "  #the output is input tensors in the form of a PyTorch tensor\n",
        "  print(input_ids)\n",
        "# Generate embeddings for the question tokens\n",
        "question_embeddings = generate_embeddings(question_tokens)\n",
        "\n",
        "# Generate embeddings for the paragraph tokens\n",
        "paragraph_embeddings = generate_embeddings(paragraph_tokens)\n"
      ],
      "metadata": {
        "id": "CaiBclf4q4AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def cosine_similarity(emb1, emb2):\n",
        "    similarity = 1 - spatial.distance.cosine(emb1, emb2)\n",
        "    return similarity\n",
        "\n",
        "#note\n",
        "#in this we have to give the axes so for each paragraph in the func defined\n",
        "#so the word embeddings should be stored in a list, that list hould be passed the function\n",
        "#like below given hashtags\n",
        "#paragraph_embeddings = [word_embedding_1, word_embedding_2, word_embedding_3]\n",
        "#question_embeddings = [word_embedding_4, word_embedding_5, word_embedding_6]\n",
        "\n",
        "# Calculating the cosine similarity between the two paragraphs\n",
        "similarity = cosine_similarity(paragraph_embeddings, question_embeddings)\n",
        "\n",
        "# Determining which paragraph is more similar based on the similarity value\n",
        "if similarity > 0.8:\n",
        "    print(paragraph)\n",
        "else:\n",
        "    print(\"Paragraph is not similar\")\n"
      ],
      "metadata": {
        "id": "kCEO_sCjrErQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#note paragraphs embeddings means there are a lot of paragraphs' embeddings *****\n",
        "def find_most_similar(question_embeddings, paragraphs_embeddings):\n",
        "  max_similarity = -1\n",
        "  most_similar_paragraph = None\n",
        "  for i, paragraph_embedding in enumerate(paragraphs_embeddings):\n",
        "    similarity = cosine_similarity(question_embeddings, paragraph_embedding)\n",
        "    if similarity > max_similarity:\n",
        "      max_similarity = similarity\n",
        "      most_similar_paragraph = i\n",
        "  return most_similar_paragraph, max_similarity"
      ],
      "metadata": {
        "id": "vFwK5oefrIxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}